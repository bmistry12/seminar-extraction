< 0.05.11.91.12.34.04.jean+ @ A.GP.CS.CMU.EDU ( <speaker>Jean Harpley </speaker>  ) .0 > Type : cmu.cs.robotics Topic : Goldfarb Seminar Dates : 18-Nov-91 Time : <stime>4:00PM</stime> PM Host : Tom <speaker>Mitchell </speaker> Appointments : <speaker>Jean Harpley </speaker>  , x3802 , <speaker>Jean </speaker> @ cs PostedBy : jean+ on 05-Nov-91 at <stime>12:34</stime> from A.GP.CS.CMU.EDU ( <speaker>Jean Harpley </speaker>  ) Abstract : Special Seminar RECONFIGURABLE LEARNING MACHINES : A NEW SYMBIOSIS OF THE DISCRETE AND THE CONTINUOUS Lev Goldfarb Faculty of Computer Science University of New Brunswick Fredericton , NB , CANADA Monday ,  18 <stime>4:00PM</stime> PM , Wean 4605 Reconfigurable learning machines are embodiments of the Evolving Transformation Systems ( ETS ) , a new mathematical model proposed resently by the speaker. < sentence > The development of the ETS was motivated by the unification of the two basic analytical paradigms , continuous and discrete : one , in which the objects are represented as elements of a finite-dimensional vector space , and the other , in which the objects are represented as strings , trees , etc. < /sentence > < sentence > Within the first paradigm , very efficient learning algorithms have been developed , mainly due to the presence of the classical continuous structure ( on the vector space ) . < /sentence > < sentence > The second paradigm offers in some sense a more satisfactory object description that can be linked more naturally to various propositional object ( class ) descriptions. < /sentence > < sentence > Neural nets and other classical pattern recognition systems belong to the first paradigm , while examples of the systems that belong to the second paradigm are syntactic ( based on the generative grammars ) learning systems as well as the version space based systems. < /sentence > < sentence > ETS represents a fundamentally new learning model , in which in the classical production system ( transformation system , TS ) a very natural competing family of distance functions is introduced : a nonnegative weight is assigned to each production and the distance between two objects is defined as the length of the shortest weighted sequence of productions necessary to transform one object into the other. < /sentence > < sentence > During learning , which is an optimization process , one or several of these distances ( i.e. < /sentence > < sentence > the corresponding weight vectors ) inducing appropriate metric structures in the set of all objects is selected. < /sentence > < sentence > However , the critical feature of the ETS is the possibility of efficient modification of the current set of productions in the TS during learning , thus generating an evolving sequence of TS , each providing more accurate means for both the learning class recognition and description. < /sentence > < sentence > Host : Tom <speaker>Mitchell </speaker> Appointments : <speaker>Jean Harpley </speaker>  , x3802 , <speaker>Jean </speaker> @ cs < /sentence >