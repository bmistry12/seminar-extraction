<paragraph><sentence>
RI SEMINAR</sentence></paragraph>

<paragraph><sentence> WHEN:		Friday, 16 Ocotober 1992, <stime>3:30 </stime>- <etime>5:00 pm</etime>
		Refreshments to be served by 3:15 pm</sentence></paragraph>

<paragraph><sentence> WHERE:		DOHERTY HALL 2315 (*NOTE ROOM*)</sentence></paragraph>

<paragraph><sentence> SPEAKER:		Gregory D. Hager - 
 		Department of Computer Science
 	 	Yale University</sentence></paragraph>

<paragraph><sentence> TITLE:		Techniques for Task-Directed Sensor Data 
 		Fusion and Sensor Planning</sentence></paragraph>

<paragraph><sentence>The growing popularity of flexible, high-bandwidth sensing in robotic systems has posed many new problems for the control of sensors and sensor information processing.</sentence><sentence>My approach to these problems assumes that the objective of sensing is to minimize effort while maximizing the likelihood of a good or correct decision.</sentence><sentence>In general, any further quantification of the latter depends heavily on the specifics of a given robot task, so I refer to this approach as ``task-directed'' sensing.</sentence></paragraph>

<paragraph><sentence>This talk describes and compares two complementary approaches to solving task-directed sensing problems.</sentence><sentence>The first approach employs decision-theoretic methods for quantifying the value of sensor information, and relies on a novel, grid-based approximation to Bayes' theorem for combining information and representing uncertainty.</sentence><sentence>I describe the application of these methods to a tracking-based vision system with controllable focus of attention and briefly present some experimental results.</sentence></paragraph>

<paragraph><sentence>The second approach employs a set-based representation of uncertainty.</sentence><sentence>Rather than optimizing a statistical criterion, the goal of this method is to satisfy a system of inequality constraints that represent both sensor information and task-specific decision criteria.</sentence><sentence>While doing so, the system adapts its data processing and data representation to the available sensor data and decision criteria.</sentence><sentence>I show several examples, taken from the manipulation domain, where adding task constraints to the sensing probl</sentence></paragraph>

<paragraph><sentence>em significantly improves processing performance.</sentence><sentence>In situations where multiple objects are present, this adaptation leads to a natural, task-directed, focus-of-attention mechanism.</sentence></paragraph>

<paragraph><sentence>Finally, depending on time and interest, I will briefly discuss work on generalizing set-based methods to unstructured environments, and also outline recent work in sensor planning for controlling actions.</sentence></paragraph>

<paragraph><sentence>Hosted By:  Hagen Schempf,  x6884</sentence></paragraph>

<paragraph><sentence>****************|**************************|**************************
*               |                          |                         *
*Tim Meadows    |  Field Robotics Center   | Carnegie Mellon Univ.</sentence><sentence>*
*               |                          |                         *
*412-268-7085   |  Fax: 412-682-1793       | tmeadows@frc.ri.cmu.edu *
*               |                          |                         *
**********************************************************************</sentence></paragraph>

<paragraph></paragraph>